{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16start.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1TUmdRl3oHvUs885CfP9ICq_eTVEdgW8L",
      "authorship_tag": "ABX9TyPhnwoFxIYOouKZkuGs/BfB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PARULCHUTANIPC/parul/blob/p1/Dogs%20Vs%20Cats%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvzO9IDXluGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArhEICDz2mN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4p4JJJ0unjy",
        "colab_type": "text"
      },
      "source": [
        "## **PREPARING THE VGG16 MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_SxJpDuwm_",
        "colab_type": "text"
      },
      "source": [
        "**Importing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJpWgUX1lZ6h",
        "colab_type": "code",
        "outputId": "eb940b5d-3f39-4d1e-cd9f-a4646b4f29b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "vgg16 = keras.applications.vgg16.VGG16()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2LtbDArl5fg",
        "colab_type": "code",
        "outputId": "98374ecb-a55c-4bf3-e7ed-f644cbb43be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        }
      },
      "source": [
        "vgg16.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_cPxjPcwk4v",
        "colab_type": "text"
      },
      "source": [
        "**Removing the output layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI8okfOXvJsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "# show a summary of the base model\n",
        "print(\"[INFO] summary for base model...\")\n",
        "print(baseModel.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHGjQ3JTwplG",
        "colab_type": "text"
      },
      "source": [
        "**Adding the output layer according to dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vzEOjMZvJnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "'''\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "'''\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "# loop over all layers in the base model and freeze them so they will\n",
        "# *not* be updated during the first training process\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzFCC67Mwv26",
        "colab_type": "text"
      },
      "source": [
        "**Compiling the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9by2KIwvJkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile our model (this needs to be done after our setting our\n",
        "# layers to being non-trainable)\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = tf.keras.optimizers.Adam(lr=1e-4)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCzi2uWivJiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZSHqQ2vJgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7_awC2FppEu",
        "colab_type": "text"
      },
      "source": [
        "## **PREPARING THE DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbX-mfq4po_Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMOpOiDvrLvk",
        "colab_type": "code",
        "outputId": "25e2dffe-ce7a-4e65-a451-643bddc9103f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/Colab Notebooks/DATASETS/DOGS VS CATS/dogs-vs-cats.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAlagg2Gy358",
        "colab_type": "code",
        "outputId": "5909c7c4-24c1-4c20-8d02-95498d8caa3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "train_images = \"/content/train.zip\"\n",
        "with ZipFile(train_images,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdzTgUo3zF8k",
        "colab_type": "code",
        "outputId": "326ac096-b443-42e7-d007-4220533be341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from zipfile import ZipFile\n",
        "test_images = \"/content/test1.zip\"\n",
        "with ZipFile(test_images,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGu5wZmVxILx",
        "colab_type": "text"
      },
      "source": [
        "**Defining the parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2I3uhRMzQlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_width, image_height = 224,224\n",
        "training_data = train_images\n",
        "test_data = test_images\n",
        "no_of_training_samples = 1000\n",
        "epochs = 10\n",
        "batch_size =20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epCxImJLxPCT",
        "colab_type": "text"
      },
      "source": [
        "**Checking the image format - Channels-width-hight or  width-height-channels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upyS5qSZzWuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, image_width, image_height)\n",
        "else:\n",
        "  input_shape = (image_width, image_height, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bonVjAz8xezy",
        "colab_type": "text"
      },
      "source": [
        "**Setting the parameters of the newly generated images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPrH9i9BzYIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data_generation = ImageDataGenerator(rotation_range=90, shear_range=0.2, horizontal_flip=True, vertical_flip=True, rescale=1/255, zoom_range=0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JITK6bvTztmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_generation = ImageDataGenerator(rescale=1/255)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy40V95Nxk1l",
        "colab_type": "text"
      },
      "source": [
        "**Generating the images using image data generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quOxkD6psHlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "502ccdef-962b-428d-f365-184588a416e0"
      },
      "source": [
        "training_generator = training_data_generation.flow_from_directory(\n",
        "    \"training_data\",\n",
        "    target_size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = batch_size,\n",
        "    class_mode = 'binary'\n",
        "\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ce74c1b71add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#class_mode = 'binary'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwTdteuvxymU",
        "colab_type": "text"
      },
      "source": [
        "## **TRAINING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3-onYKbtGUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    training_generator,\n",
        "    steps_per_epoch = no_of_training_samples,\n",
        "    epochs = epochs\n",
        "\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXNjxfigxtFJ",
        "colab_type": "text"
      },
      "source": [
        "**Saving the weights & model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJ2WontyZH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"dogs-cats-try1.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc594l4ayjAJ",
        "colab_type": "text"
      },
      "source": [
        "**Selecting 1 image to verify the working of model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbqXOgu7ysfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_pred = image.load_img(\"       \",target size = (224,224))\n",
        "image_pred = image.img_to_array(image_pred)\n",
        "image_pred = np.expand_dims(image_pred, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ftl8h1oyr4T",
        "colab_type": "text"
      },
      "source": [
        "**Testing the single uploaded image & Verify the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAdprvz6ysbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.predict(image_pred)\n",
        "print(image_pred)\n",
        "if result[0][0] ==1:\n",
        "  prediction = \"This is a Dog\"\n",
        "else:\n",
        "  prediction = \"This is a Cat\"\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}